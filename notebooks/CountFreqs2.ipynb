{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from osp import *\n",
    "\n",
    "df_meta = get_corpus_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33685401",
   "metadata": {},
   "outputs": [],
   "source": [
    "SLICE_LEN = 1000\n",
    "slice_len = SLICE_LEN\n",
    "stash = HashStash(f'osp_slices_{slice_len}')\n",
    "stash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18785109",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_recog_words(txt):\n",
    "    return [\n",
    "        w.lower() for w in tokenize_agnostic(txt)\n",
    "        if w.strip().isalpha() and w.lower() in get_ok_words()\n",
    "    ]\n",
    "\n",
    "def count_recog_words(txt, n=SLICE_LEN):\n",
    "    return Counter(get_recog_words(txt.lower())[:n])\n",
    "\n",
    "def get_text_freqs(id, slice_len=SLICE_LEN, force=False):\n",
    "    stash = HashStash(f'osp_freqs_slices_{slice_len}')\n",
    "    if not force and id in stash:\n",
    "        return {int(k):v for k,v in stash[id].items()}\n",
    "    slices = get_text_slices(id)\n",
    "    freqs = {\n",
    "        int(slice_num): dict(count_recog_words(txt, slice_len))\n",
    "        for slice_num, txt in slices.items()\n",
    "    }\n",
    "    stash[id] = freqs\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_text_freqs('phil/10.2307/40231690',force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723449e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_recog_words('Hello, eee ex world!\\n' * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5df937",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in tqdm(df_meta.index):\n",
    "    get_text_freqs(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374d5968",
   "metadata": {},
   "outputs": [],
   "source": [
    "STASH_SLICE_WORD_FREQS = HashStash('osp_freqs_slices_1000')\n",
    "STASH_SLICE_WORD_FREQS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd63b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in STASH_SLICE_WORD_FREQS.items():\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365dcde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_slice_word_freqs(df_meta=None):\n",
    "    df_meta = get_corpus_metadata() if df_meta is None else df_meta\n",
    "    for id in tqdm(df_meta.index):\n",
    "        for slice_num, freqs in get_text_freqs(id).items():\n",
    "            yield id, slice_num, freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8427059",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = Counter()\n",
    "for id, slice_num, freqs in iter_slice_word_freqs():\n",
    "    for w in freqs:\n",
    "        num_docs[w] += 1\n",
    "\n",
    "num_docs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee5751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs_s = pd.DataFrame({'num_docs': num_docs}).rename_axis('word')\n",
    "num_docs_s['num_docs_rank'] = num_docs_s['num_docs'].rank(method='min', ascending=False).apply(int)\n",
    "num_docs_s.sort_values('num_docs_rank', ascending=True, inplace=True)\n",
    "# num_docs_s.to_csv('../data/worddb_counts.csv')\n",
    "num_docs_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "41009934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_freqs_slices(words, slice_len=SLICE_LEN):\n",
    "    stash = HashStash(f'osp_word_freqs_slices_{slice_len}')\n",
    "    # stash.clear()\n",
    "    if not any(w not in stash for w in words):\n",
    "        word2text2count = {\n",
    "            w: stash[w]\n",
    "            for w in words\n",
    "        }\n",
    "    else:        \n",
    "        word2text2count = defaultdict(dict)\n",
    "        for id, slice_num, freqs in iter_slice_word_freqs():\n",
    "            for w, c in freqs.items():\n",
    "                if w in words:\n",
    "                    word2text2count[w][f'{id}__{slice_num:02d}'] = c\n",
    "\n",
    "        for k,v in tqdm(list(word2text2count.items()), desc='saving to stash'):\n",
    "            stash[k] = v\n",
    "\n",
    "        for w in words:\n",
    "            if w not in stash:\n",
    "                word2text2count[w] = {}\n",
    "\n",
    "    return pd.DataFrame(word2text2count).rename_axis('id__slice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d16b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>LMDBHashStash</pre><table border=\"1\" class=\"dataframe\"><thead><tr><th>Config</th><th>Param</th><th>Value</th></tr></thead><tbody><tr><td><b>Path</b></td><td>Root Dir</td><td><i>/Users/rj416/.cache/hashstash/osp_word_freqs_slices_1000</i></td></tr><tr><td><b></b></td><td>Filename</td><td><i>data.db</i></td></tr><tr><td><b>Engine</b></td><td>Engine</td><td><i>lmdb</i></td></tr><tr><td><b></b></td><td>Serializer</td><td><i>hashstash</i></td></tr><tr><td><b></b></td><td>Compress</td><td><i>lz4</i></td></tr><tr><td><b></b></td><td>B64</td><td><i>True</i></td></tr><tr><td><b>Stats</b></td><td>Len</td><td><i>641</i></td></tr></tbody></table>"
      ],
      "text/plain": [
       "LMDBHashStash(~/.cache/hashstash/osp_word_freqs_slices_1000/lmdb.hashstash.lz4+b64/data.db)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stash = HashStash(f'osp_word_freqs_slices_1000')\n",
    "# stash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1d18b1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 5124/57620 [00:24<04:13, 206.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rj416/github/ordinary-style-philosophy/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3701, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/d9/tm2sn8_12xsc6p6nfgtrd5h40000gp/T/ipykernel_84192/125031490.py\", line 3, in <module>\n",
      "    df_freqs = get_words_freqs_slices(words)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/d9/tm2sn8_12xsc6p6nfgtrd5h40000gp/T/ipykernel_84192/1004263686.py\", line None, in get_words_freqs_slices\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/rj416/github/ordinary-style-philosophy/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2201, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rj416/github/ordinary-style-philosophy/venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rj416/github/ordinary-style-philosophy/venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1064, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rj416/github/ordinary-style-philosophy/venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 872, in structured_traceback\n",
      "    formatted_exceptions: list[list[str]] = self.format_exception_as_a_whole(\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rj416/github/ordinary-style-philosophy/venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 784, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rj416/github/ordinary-style-philosophy/venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 540, in format_record\n",
      "    assert isinstance(frame_info.lineno, int)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "words = get_non_content_words()\n",
    "# words =['insofar']\n",
    "df_freqs = get_words_freqs_slices(words)\n",
    "df_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e9ce9075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_freqs.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs_s.loc['insofar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6699ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_content_words = get_non_content_words()\n",
    "num_docs_s['is_non_content'] = num_docs_s.index.isin(non_content_words)\n",
    "num_docs_s[num_docs_s.is_non_content].query('num_docs_rank < 10_000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e7021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
