{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YZhIry5Gg3kZ"
      },
      "outputs": [],
      "source": [
        "import sys; sys.path.append('..')\n",
        "from osp import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dFao4rxn-Src"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre>LMDBHashStash</pre><table border=\"1\" class=\"dataframe\"><thead><tr><th>Config</th><th>Param</th><th>Value</th></tr></thead><tbody><tr><td><b>Path</b></td><td>Root Dir</td><td><i>/Users/ryan/.cache/hashstash/osp_slices_1000_nlp</i></td></tr><tr><td><b></b></td><td>Filename</td><td><i>data.db</i></td></tr><tr><td><b>Engine</b></td><td>Engine</td><td><i>lmdb</i></td></tr><tr><td><b></b></td><td>Serializer</td><td><i>hashstash</i></td></tr><tr><td><b></b></td><td>Compress</td><td><i>lz4</i></td></tr><tr><td><b></b></td><td>B64</td><td><i>True</i></td></tr><tr><td><b>Stats</b></td><td>Len</td><td><i>8756</i></td></tr></tbody></table>"
            ],
            "text/plain": [
              "LMDBHashStash(~/.cache/hashstash/osp_slices_1000_nlp/lmdb.hashstash.lz4+b64/data.db)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_stash = HashStash('osp_slices_1000_nlp')\n",
        "input_stash\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UNxuppgkM5Hq",
        "outputId": "16256851-a3a8-4a7e-9675-c5444dec64b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'phil/10.2307/20140633__02'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "key,docstr = next(input_stash.items())\n",
        "doc = stanza.Document.from_serialized(docstr)\n",
        "word = doc.sentences[1].words[5]\n",
        "key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Qa6yfyDVdW4P"
      },
      "outputs": [],
      "source": [
        "def get_word_context(doc, sent_i, word_i, context_len=2):\n",
        "    sent = doc.sentences[sent_i]\n",
        "\n",
        "    prev_context=''\n",
        "    next_context=''\n",
        "\n",
        "    words_forward=sent.words[word_i+1:]\n",
        "    words_backward=reversed(sent.words[:word_i])\n",
        "    for w in words_forward:\n",
        "        if len(next_context) < context_len:\n",
        "            next_context+=w.text+' '\n",
        "        else:\n",
        "            break\n",
        "    for w in words_backward:\n",
        "        if len(prev_context) < context_len:\n",
        "            prev_context=w.text+' '+prev_context+' '\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    word = sent.words[word_i]\n",
        "    out = f'{prev_context.strip()} {word.text.upper()} {next_context.strip()}'\n",
        "    out = out.replace('\\n',' ').replace(' ,',',').replace(' .', '.').replace(' !','!').replace(' ?','?').replace( ':',':').replace(' ;',';')\n",
        "    out = out.replace('( ','(').replace('[ ','[').strip().replace(' )',')').replace(' ]',']').replace('\"', ' ').replace(\"'\",\" \")\n",
        "    return remove_left_right_punct(out.strip()).strip()\n",
        "\n",
        "FEAT_N = 100\n",
        "FEAT_MIN_COUNT = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YzrQsEobNBtK"
      },
      "outputs": [],
      "source": [
        "STASH_POS_COUNTS = HashStash('osp_slices_1000_pos_counts')\n",
        "STASH_FEAT2WORD2COUNT = HashStash('osp_slices_1000_feat2word2count')\n",
        "STASH_FEAT2WORD2EG = HashStash('osp_slices_1000_feat2word2eg')\n",
        "CONTEXT_LEN = 15\n",
        "\n",
        "\n",
        "def get_pos_counts(doc, feat2word2count=None, feat2word2eg=None, context_len=CONTEXT_LEN):\n",
        "    pos_counts = Counter()\n",
        "    deprel_counts = Counter()\n",
        "    if feat2word2count is None: feat2word2count = defaultdict(Counter)\n",
        "    if feat2word2eg is None: feat2word2eg = defaultdict(dict)\n",
        "\n",
        "    for sent_i,sent in enumerate(doc.sentences):\n",
        "        for word_i,word in enumerate(sent.words):\n",
        "            if word.pos in {'X'} or word.deprel in {'flat'}:\n",
        "                continue\n",
        "            pos = word.xpos\n",
        "            deprel = word.deprel\n",
        "            pos_counts[pos]+=1\n",
        "            deprel_counts[deprel]+=1\n",
        "\n",
        "            eg_word = word.text.lower()\n",
        "            if feat2word2count is not None:\n",
        "                feat2word2count[deprel][eg_word]+=1\n",
        "                feat2word2count[pos][eg_word]+=1\n",
        "\n",
        "            if feat2word2eg is not None:\n",
        "                eg_context = get_word_context(doc, sent_i, word_i, context_len=context_len).strip()\n",
        "                feat2word2eg[deprel][eg_word] = eg_context\n",
        "                if not eg_word in feat2word2eg[pos]:\n",
        "                    feat2word2eg[pos][eg_word] = eg_context\n",
        "\n",
        "    sum_pos_counts = sum(pos_counts.values())\n",
        "    # print(sum_pos_counts)\n",
        "    pos_counts_rel = {k:int(round(v/sum_pos_counts*1000)) for k,v in pos_counts.items()}\n",
        "\n",
        "    sum_deprel_counts = sum(deprel_counts.values())\n",
        "    deprel_counts_rel = {k:int(round(v/sum_deprel_counts*1000)) for k,v in deprel_counts.items()}\n",
        "\n",
        "    return {**pos_counts_rel,**deprel_counts_rel}, feat2word2count, feat2word2eg\n",
        "\n",
        "def gen_pos_counts(id, force=False):\n",
        "    if not force and id in STASH_POS_COUNTS and id in STASH_FEAT2WORD2COUNT and id in STASH_FEAT2WORD2EG:\n",
        "        return STASH_POS_COUNTS[id], STASH_FEAT2WORD2COUNT[id], STASH_FEAT2WORD2EG[id]\n",
        "    \n",
        "    docstr = input_stash[id]\n",
        "    doc = stanza.Document.from_serialized(docstr)\n",
        "    counts, feat2word2count, feat2word2eg = get_pos_counts(doc)\n",
        "    STASH_POS_COUNTS[id] = counts\n",
        "    STASH_FEAT2WORD2COUNT[id] = feat2word2count\n",
        "    STASH_FEAT2WORD2EG[id] = feat2word2eg\n",
        "    return counts, feat2word2count, feat2word2eg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "ids = list(input_stash.keys())\n",
        "random.shuffle(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8756/8756 [02:50<00:00, 51.43it/s]\n"
          ]
        }
      ],
      "source": [
        "for id in tqdm(ids):\n",
        "    gen_pos_counts(id, force=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
