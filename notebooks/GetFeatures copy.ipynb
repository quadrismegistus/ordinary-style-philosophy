{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226b669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from osp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f5832db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_corpus_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a62a112b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello\\n\\n\\nworld!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dehyphenate(nltk.sent_tokenize(\"Hello\\n\\n\\nworld!\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f56e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "id,txt = next(iter_corpus_txt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d051f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is one of the relatively few deliberate jokes in the corpus, and its occurrence here is not without significance.\n",
      "Aristotle in these chapters is arguing against those who believe in the existence of the void, or vacuum, or empty space; he says, 'even if we consider it on its own merits the so-called vacuum will be found to be really vacuous.\n",
      "He seems to refuse to take the hypothesis of the void at all seriously.\n",
      "Jack Macintosh made very useful comments on that occasion.\n",
      "That paper lay asleep in a drawer for several years until Kant's remarks on density (in the Anticipations of Perception) sent me back to it.\n",
      "Andrew Lugg has read several approximations to this final version, and has given me careful and generous comments on them.\n",
      "It seems to me more likely that the motives are reasons, reasons having to do with physics, and probably reasons lying deep in his physical system.\n",
      "I expect the problem lies in our imaginative difficulty in entering his viewpoint from our own, in shedding the presuppositions and certainties of our own physics.\n",
      "Solmsen writes, 'His objections are not of a metaphysical or ontological nature; they keep strictly to the sphere of physics.\n",
      "In what follows I shall use the unusual phrase 'plena-and-void' instead of the more usual 'atoms-and-void' to denote atomism.\n",
      "The reason is that the feature of atoms which will preoccupy me is not their indivisibility a feature that is variously understood but the fact that they are all plena, equally, perfectly, and utterly dense.\n",
      "It is not part of this view that there are no sharp boundaries between middle-sized objects or tracts of substance.\n",
      "What I want to do in this paper is to lead and cajole the reader, as it were, into Aristotle's boots; I want to get our heads inside Aristotle's continuum theory of matter: from that vantage point his discussion of the void will seem less perverse and less barren.\n",
      "Perhaps I shall not be able to make the denial of void respectable, but I hope at least to be able to make it understandable.\n",
      "In the main, I am not wanting to study or rehearse Aristotle's actual surface arguments about the void; rather, I want to dig behind the position and show that even the most vexatious junctures of his discussion are in fact dictated by the internal logic of his continuum theory.\n",
      "We can begin by clearing up what Aristotle means at various places in these chapters when he speaks of the separate and unseparate or separable and unseparable void.\n",
      "This will divide up the subject matter for us, and give us a plan of attack.\n",
      "The easiest sort to comprehend is the absolutely separate void, empty space extending beyond the periphery of the world.\n",
      "The middle sort in each list the actual void or the separate void in the rare are the pockets of empty space which separate atoms in any substance which is not completely dense.\n",
      "But it only directly precludes one of the three kinds of void.\n",
      "My argument will be that its implications led Aristotle also to preclude the other kinds.\n",
      "The translation should be: it is not then the existence of air that needs to be proved, but the nonexistence of an extension, different from bodies, whether separable, or actually separate so as to break the continuity of body....\n",
      "I know of no English translation which has reflected this point.\n",
      "Perhaps the diffused void occurs in smaller pockets, but small pockets of void are nonetheless pockets of void; they seem not to differ in principle from larger ones.\n",
      "But if you look closely matters are not perhaps as bad as they seem at first.\n",
      "This frustrating indeterminacy of technical language can be found elsewhere in Aristotle, e.g.\n",
      "As we conceptually diffuse void through bodies more and more completely all we manage to do is to make the pockets smaller and smaller.\n",
      "To make them disappear altogether is not possible, for then we should have pure plenum.\n",
      "But Aristotle of course did not believe in the void; he had a continuum theory of matter.\n",
      "So what he surely has in mind here is a perfect diffusion of void in bodies, such diffusion that the pockets of void have no size.\n",
      "Suppose we take a pot and fill it halffull of perfectly dense matter and half-full of void.\n",
      "Then we take a beater and with it break up the matter quite fine and spread it through the pot.\n",
      "According to our plena-and-void physics, however hard and long we beat the matter, we shall always have chunks of dense matter ultimately very very small chunks spread through the void.\n",
      "But the other view, my view, also has a pedigree.\n",
      "P.M. Maggidlo, O.P.\n",
      "I think that Themistius, Aquinas and I have a better interpretation than do Simplidus, Philoponus and Wicksteed, for the following reason.\n",
      "The first of these is that the void will turn out to be the condition not of all movement but only of movement upwards; but this would not be true of interatomic voids, for they are a condition of all movement: it is the voids in a fluid which (on the atomists' theory) allow a body to move through it, by allowing the atoms to move out of the way.\n",
      "Only a void which does not break the continuity of body, a void coterminous with body, would fail to be a condition of all movement and so be confined to being a condition of movement upwards, as a lightening agent.\n",
      "Aristotle's first reason for rejecting the idea of this kind of void is incompatible with Simplicius' and Philoponus' and Wicksteed's understanding of this kind of void.\n",
      "But the chunks themselves are always perfectly dense and the void is always perfectly vacant.\n",
      "A continuum theorist, however, will not have this constraint.\n",
      "For a continuum theorist there is no difficulty about making the matter and void in the pot into a PERFECTLY SMOOTH CREAM so that the pieces of dense matter in it are of no size and the tracts of void are of no size.\n",
      "An infinitely slender dipstick dipped into this cream will not encounter alternate jots of matter and void, but an entirely homogeneous substance.\n",
      "Any part of this substance, no matter how tiny, will be identical in nature with any other part.\n",
      "This story of mixing up a perfectly smooth cream allows us to reach the viewpoint of a continuum theorist from our own; but of course for the continuum theorist the world comes ready-made as a continuum.\n",
      "It is a very natural commonsense view, and it is older than atomism.\n",
      "We have travelled some way to reach this continuum theory; but what we have reached, I suggest, is the place from which Aristotle began.\n",
      "Having accepted such a continuum theory as natural, let us see how strange and confused a potential void theory must appear.\n",
      "We can begin by taking our pot of perfectly smooth cream, our substance of middle density, and trying on the idea of the atomists that what makes it be of middle density is that it contains half matter and half void.\n",
      "Let us try to separate out the matter and the void, and see how much of each there is.\n",
      "We gather all the matter into the lower half of the pot, leaving vacancy in the upper half: the arrangement with which the experiment began.\n",
      "But and this is the crucial point why should we stop there?\n",
      "Because, ex hypothesi, the matter is now perfectly dense, you say; but that judgment is made from the point of view of plena-and-void physics.\n",
      "Why should there be such a thing as absolute density?\n",
      "A continuum theory can naturally suppose that there is no upper or lower limit to the density of things.\n",
      "If we have difficulty accepting this, it is because we have not really left our plena-and-void presuppositions behind.\n",
      "So the matter which occupies half the pot can be further compressed, so that it occupies only a quarter of the pot.\n",
      "And it can be further and further compressed, ultimately to infinitesimal size.\n",
      "Now, we were trying to test the supposition of the atomists that what made our perfectly smooth cream be of middle density was that it contained equal parts of body and void.\n",
      "But it seems that that is purely arbitrary; if we compress the body enough, the quantity of void that will be found will be equal to the initial volume of the pot of cream.\n",
      "Bizarre.\n",
      "To fix upon a certain determinate amount of void in any block of a substance is to fix upon a density of body which is perfect or absolute density; to fix upon an idea of perfect density is already to subscribe to a plena-and-void physics.\n",
      "So naturally the idea that pots of lead and air differ in density by having different quantities of void in them will seem counterintuitive to a continuum theorist.\n",
      "It will then be impossible to use the hypothesis of a diffused void to account for different densities of two equal-sized lumps of substance: both will contain the same amount of void.\n",
      "Aristotle writes succinctly of this problem: when the lightening void carries something upwards, liow can void have a local movement or a place?\n",
      "For thus that into which void moves is till then void of a void.\n",
      "Either alternative is embarrassing.\n",
      "But this problem arises as much for the notion of void as 'separate in the rare' as it does for potential void, so let us turn to that conception.\n",
      "Descartes, who identified matter with extension, held that matter was utterly rigid.\n",
      "It seems clear that Aristotle allows the compressibility of matter, even though, as we shall see, he identifies matter with extension; extension for Aristotle is not absolute space, of course, but space dependent on and constituted by bodies.\n",
      "The void is thought of as a sort of lightening agent, like helium in a balloon.\n",
      "Another joke?\n",
      "The notion of a separate void, dispersed in pockets in the rare, however, does directly contradict the continuum theory.\n",
      "One comes away from reading about the separate void wondering whether Aristotle believes that there cannot be such a thing as separate void, or that there could be but isn't.\n",
      "I think that his general line is probably more sophisticated: a continuum theory is perfectly adequate to account, with simplicity and ease, for the phenomena which the separate void is adduced to explain, movement and compression; hence the hypothesis of the void is explanatorily redundant.\n",
      "Moreover, the plena-and-void theory which also accounts for these phenomena has a certain incoherence in its conception of the void.\n",
      "Or rather, there is such a problem only if one supposes body to be absolutely rigid and unyielding.\n",
      "But (a) we have just seen that, in a continuum theory, there is no difficulty in principle about bodies' being compressed and (b) it would be a natural inference from experience that some of the world continuum is fluid.\n",
      "There is, then, no more difficulty about things moving in continuous matter than about grains of sand moving about in the sea.\n",
      "Once we wish away that commitment there is no prima facie problem about the motion of objects.\n",
      "But there is a problem in the adduction of the void to explain motion and compression.\n",
      "On the one hand the void is thought of as a sort of stuff a lightening agent I called it above when it is used to explain rarity; on the other hand it is thought of as motionless space when it is used to explain how motion is possible.\n",
      "Let me try to make this incoherence acute with a modern example.\n",
      "Take a bell jar and evacuate it.\n",
      "We have then a certain tract of void within the jar.\n",
      "Now move the jar to the other side of the room.\n",
      "Do you still have the same tract of void inside the jar, or do you have a different one?\n",
      "Conceiving void as a lightening agent, you still have the same tract; the tract has been isolated and can be carried about.\n",
      "This is the conception of void that is natural when it is used to explain the lightness of things.\n",
      "On the other hand if you conceive void as the absolute space of the universe, the natural conception when you seek to explain motion, you have to say that when the bell jar is moved it comes to contain a different tract of void.\n",
      "At this point one might want to object something like the following.\n",
      "Void is nothing; to talk about different tracts of void is to talk about different bits of nothing.\n",
      "It is surreptitiously to treat nothing as though it were something.\n",
      "It is to fall victim to one of the oldest tricks in the book, that of wily Odysseus who told the Cyclops that his name was Nobody.\n",
      "This objection can, however, be resisted.\n",
      "Suppose you are wanting to establish a value for the permittivity of empty space; like a good scientist you would want to take the measurement on a number of different samples and then average the results.\n",
      "You set up your capacitor plates and recording devices in the jar, and evacuate it.\n",
      "Then you take a measurement of the permittivity of the void inside the jar.\n",
      "Now, if you think of the void as an absolute tract of space you can take measurements of other samples of void just by moving the jar around, without breaking its seal and reevacuating it.\n",
      "In each new place that you put the evacuated jar it will contain a new stretch of void, and you can measure the permittivity of this new sample.\n",
      "On the other view, once you evacuate the jar you have isolated and imprisoned a certain tract of void, and wherever you move the jar you carry the same tract of void with you, and so you would merely be remeasuring the same sample.\n",
      "It is measured in farads per metre.\n",
      "This seems a nontrivial value.\n",
      "Aristotle, so far from being superficial in his treatment of the matter, has put us a question which, for all our cocksure acceptance of the obvious truth of plena-and-void physics, we cannot readily answer.\n",
      "His difficulty with ancient conceptions of void is also a difficulty for our conception of it.\n",
      "The dialectical state, then, is this.\n",
      "A continuum theory of matter, which is a very natural theory, read straight off our experience of the world, is able without contortion or obscurity to account for motion and compression.\n",
      "Those who seek to introduce a newfangled plenaand-void theory seem perverse: there are no explanatory gains, and there seems to be this deep incoherence in their idea of void, as between a very very rare stuff, and absolute space.\n",
      "The theory that the world is made of void and plena, then, seems not very attractive.\n",
      "But there is a residual worry.\n",
      "One wants to know whether, even if the world comes as a continuum, one could artificially create a void in it: could one evacuate a tract of space?\n",
      "Could one, against nature, empty a jar of all body?\n",
      "At times Aristotle seems to be saying that one could not, and here our sympathy runs to its lowest ebb.\n",
      "We want to say that, whatever the practical difficulties, at least conceptually it is possible to reach into a pot and pull out all the body, stopping other body from flowing in.\n",
      "But think for a moment how we are likely to conceive of this.\n",
      "We conceive of it, roughly, in the following way.\n",
      "We get most of the body out with a spoon, and then for the last remaining bits we go in with a pair of tweezers and pull out the body, atom by atom.\n",
      "But that conception will only work in a plenaand-void physics.\n",
      "Switch to a continuum physics and it is not at all clear how you will get all the body out.\n",
      "Indeed when you remember that in a continuum theory the notion of maximum or minimum density has no natural place, it seems that as you draw out body you leave a rarer and rarer residue; but this process can go on to infinity.\n",
      "In a adjust the value of the unit of charge in such a way as to give a unit value to the permittivity of empty space, but then another property of empty space, magnetic permeability, would have a nontrivial value.\n",
      "In other words, empty space inescapably has some properties of nontrivial quantity.\n",
      "But in a continuum theory there are no such quanta; the process of drawing out body will seem to be be asymptotic.\n",
      "So not only is Aristotle arguing that the world does not come readymade with pockets of void the void is a needless and incoherent hypothesis but also he can without absurdity maintain that you cannot artificially create a void.\n",
      "That claim seems to us perverse and desperate only because we judge it from within plena-and-void presuppositions.\n",
      "From within a continuum view it makes perfect sense.\n",
      "Ill Absolutely Separate Void This brings us to the most difficult sort of void to deny, the void which some say is beyond the world.\n",
      "Even if one is a continuum theorist for the subcelestiad region, it seems hard to understand why there would not, or could not, be empty space beyond the heavens.\n",
      "W.D.\n",
      "Ross).\n",
      "But surely all Aristotle's arguments in that chapter are based on the things we do or do not observe in the sublunary sphere.\n",
      "How will you stop space from being beyond?\n",
      "I think that the way for us to reach some sort of sympathetic understanding of this view of Aristotle's is to dig a little deeper into his ideas of body and space.\n",
      "In the last section we saw how it is that, from the viewpoint of a continuum theorist, it would be impossible ultimately to empty a given container of the matter that is in it; but why should it not be possible for there to be a place which simply never had matter in it in the first place?\n",
      "Does Aristotle's denial of extramundane void rest merely upon his dated kinetics and dubious modal principles, or is there something more compelling to be said for it?\n",
      "Maybe he is right that empty space is not needed for its usual explanatory role in the world but why can there not be empty space beyond the world?\n",
      "The answer, I think, leads us into some fundamental notions in Aristotle's physics.\n",
      "On the surface that answer is just that empty space spatial extension devoid of body is a flat contradiction in terms.\n",
      "That surface answer, of course, does not take us very far.\n",
      "If Aristotle is trying to refute the opposition merely by defining it into contradiction our sympathy is not likely to be very great.\n",
      "But in fact Aristotle never offers this definition as a refutation of the void, so I expect that he feels in some way caught in this definition of body, and thus seeks to find independent arguments for its contentious consequences.\n",
      "We need to try to understand why he feels caught in this definition of body.\n",
      "As a first step we should notice that the failure to mark our distinction between body and the space it occupies runs right through Aristotle's technical vocabulary.\n",
      "This systematic confusion (from our point of view) between body and spatial extension does not seem to bespeak a petulant refusal to distinguish the two; rather it seems a symptom of a genuine inability to separate the concepts.\n",
      "What is it that interferes with the clear conceptual separation of body and space?\n",
      "If we were asked what the difference is between empty space and body, I suppose we should reply that body is space which contains matter, and space is body without the matter.\n",
      "Moreover we can fill in a certain amount of conceptual terrain around this distinction.\n",
      "We can explain the different densities of two substances by saying that the one has more matter in a given space than the other in an equal space.\n",
      "We conceive of the greater amount of matter in the one than in the other as, basically, a larger number of atoms.\n",
      "And empty space is just zero density, zero atoms.\n",
      "But first it will be useful to see why he is restricted to overall volume in this way.\n",
      "Two things conspire to restrict him: his peculiar views about weight, and the fact that he does not believe in atoms.\n",
      "Let me explain this conspiracy.\n",
      "Aristotle's understanding of weight makes it a hopeless measure of quantity of matter.\n",
      "He sees weight and lightness both as positive values (one is not simply the lack of the other), and they amount to the tendency to move downwards or upwards respectively.\n",
      "He is stuck with volume.\n",
      "But being restricted to volume as the measure of matter is not in itself crippling for the development of the idea of quantity of matter.\n",
      "An atomist, after all, can easily express the quantity of matter in a given place as the total volume of atoms in it.\n",
      "And this is what leaves him hamstrung.\n",
      "The first consequence of being restricted to overall volume as the measure of quantity of matter is the primitivity of density.\n",
      "Otherwise, the universe would bulge (as Xuthus said), or it will grow and diminish, so that there must be empty space around its periphery.\n",
      "We measure density in weight per unit volume; an atomist with no useful conception of weight can measure it (theoretically) in volume of atoms per volume of substance, as we have just seen.\n",
      "The apparatus of theoretical measurement that is available to someone in Aristotle's position cannot capture the apparent difference of densities between substances.\n",
      "And if density is thus unquantifiable, the notion of zero density, of empty space, is likely to seem meaningless.\n",
      "The second consequence, though reached differently, is similar: the very intimate conceptual relationship between volume and body.\n",
      "If volume is the proper measure of body, the notion of volumes existing without body must seem strange.\n",
      "Voltage is the proper measure of electrical pressure; the idea of there being cases in which some positive value of voltage does not measure electrical pressure but rather its absence would seem to us extremely strange.\n",
      "Now those who believe in the possibility of empty space would have us believe that when I remove the body (assuming that no other body comes in to replace it) its volume, as well as being removed along with it, is also left behind.\n",
      "It would follow that every body has at any one time two volumes superimposed: one which always goes about with the body and is indissociable from it, and one which remains behind when the body moves on.\n",
      "Commentators do not generally take this equation seriously, but it may be seriously meant.\n",
      "So the question we are asking of Aristotle why can there not be empty space beyond the fixed stars has to be taken down a peg if we are to respect his viewpoint.\n",
      "It becomes: why is there not (tenuous) body beyond the fixed stars?\n",
      "And that is a question which we can allow him to answer from within his astronomical theories and his theories about actual and potential infinity; we shall not think it perverse of him to conclude that there is a limit to body.\n",
      "And once we have seen that, for anyone whose only measure of matter is volume, a limit to body is eo ipso a limit to space, we shall be less outraged by his denial of that space.\n",
      "IV Reservations I have overstated my case.\n",
      "No thinker is ever perhaps really trapped in quite the way that I have depicted Aristotle as being trapped.\n",
      "There are ways in which he could have developed a theoretical measure of quantity of matter which was more than overall volume, and there are suggestions here and there that he is groping after such a development.\n",
      "I should mention them.\n",
      "With this transformation it becomes possible to analyze and quantify densities.\n",
      "Aristotle is not, of course, a monist, but the fact that his four elements are able to transform into each other means that he might as well be.\n",
      "He need only choose one of his elements, arbitrarily, as the one in whose terms quantity of matter will be measured.\n",
      "These are the only passages I know in which such a measure of quantity of matter, relying on transformation of elements, is mentioned.\n",
      "This would give a way of quantifying density by an operational measure.\n",
      "However, it is the only passage in which this law of projectile motion is suggested, and many commentators have claimed that it is not a law in which he seriously believes, but one which he has drummed up ad hoc to refute the void.\n",
      "Still, this reflection would be enough to get a notion of quantity of matter going.\n",
      "But Aristotle does not, in fact, in the extant works at any rate, carry it any further.\n",
      "But in fact this does not take us very far.\n",
      "Aristotle is clear that this perceptibility is not to be understood crudely.\n",
      "Once we realize that it is not actual but potential perceptibility that distinguishes body from empty space it becomes hard to know how to use this criterion.\n",
      "What are the tests of potential perceptibility?\n",
      "Most commentators think it is.\n",
      "It is this entrapment, I believe, which provides the deep reason for his inability to cleave the concept of space from that of body.\n",
      "This is the real source of his horror vacui.\n"
     ]
    }
   ],
   "source": [
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c967b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(txt):\n",
    "    tokens = txt.lower().split()\n",
    "    cleaned = []\n",
    "    for t in tokens:\n",
    "        cleaned_token = t.lstrip(\"\".join([c for c in t if not c.isalpha()])).rstrip(\"\".join([c for c in t if not c.isalpha()]))\n",
    "        if cleaned_token:\n",
    "            cleaned.append(cleaned_token)\n",
    "    return cleaned\n",
    "\n",
    "STASH_COUNTS = HashStash('osp_counts')\n",
    "def count_tokens(id, force=False):\n",
    "    if not force and id in STASH_COUNTS:\n",
    "        return STASH_COUNTS[id]\n",
    "    txt = get_corpus_txt(id)\n",
    "    d = dict(Counter(tokenize(txt)))\n",
    "    STASH_COUNTS[id] = d\n",
    "    return d\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c75ef7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86402"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df = pd.read_csv('../data/raw/worddb.byu.txt',sep='\\t').set_index('word')\n",
    "ok_words = set(word_df.index)\n",
    "len(ok_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b97c2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58126/58126 [00:24<00:00, 2351.91it/s]\n"
     ]
    }
   ],
   "source": [
    "for id in tqdm(df.index):\n",
    "    count_tokens(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f5d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7da43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bounter import bounter\n",
    "# b = bounter(size_mb=16384, need_iteration=False, log_counting=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b1c21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58126/58126 [00:40<00:00, 1422.25it/s]\n"
     ]
    }
   ],
   "source": [
    "allcounts = Counter()\n",
    "philcounts = Counter()\n",
    "litcounts = Counter()\n",
    "for k,d in tqdm(STASH_COUNTS.items(), total=len(STASH_COUNTS)):\n",
    "    d = {w:c for w,c in d.items() if w in ok_words}\n",
    "    allcounts.update(d)\n",
    "    if k.startswith('phil/'):\n",
    "        philcounts.update(d)\n",
    "    else:\n",
    "        litcounts.update(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d0867f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df['count'] = word_df.index.map(allcounts)\n",
    "word_df['count_phil'] = word_df.index.map(philcounts)\n",
    "word_df['count_lit'] = word_df.index.map(litcounts)\n",
    "\n",
    "sumcount = word_df['count'].sum()\n",
    "sumphil = word_df['count_phil'].sum()\n",
    "sumlit = word_df['count_lit'].sum()\n",
    "\n",
    "word_df['fpm'] = word_df['count'] / sumcount * 1_000_000\n",
    "word_df['fpm_phil'] = word_df['count_phil'] / sumphil * 1_000_000\n",
    "word_df['fpm_lit'] = word_df['count_lit'] / sumlit * 1_000_000\n",
    "\n",
    "word_df['fpm_diff'] = word_df['fpm_phil'] - word_df['fpm_lit']\n",
    "word_df['fpm_div'] = word_df['fpm_phil'] / word_df['fpm_lit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "226a32f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59796"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(philcounts.keys()) & set(litcounts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b7a7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df['pos0'] = [pos[0] for pos in word_df['pos']]\n",
    "word_df['content_word'] = [pos[0] in {'n','v','j','r'} for pos in word_df['pos0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e80f82b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpm</th>\n",
       "      <th>fpm_phil</th>\n",
       "      <th>fpm_lit</th>\n",
       "      <th>fpm_diff</th>\n",
       "      <th>fpm_div</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>thy</th>\n",
       "      <td>46.199326</td>\n",
       "      <td>3.651140</td>\n",
       "      <td>127.796152</td>\n",
       "      <td>-124.145013</td>\n",
       "      <td>0.028570</td>\n",
       "      <td>appge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thee</th>\n",
       "      <td>28.442756</td>\n",
       "      <td>2.438765</td>\n",
       "      <td>78.311934</td>\n",
       "      <td>-75.873169</td>\n",
       "      <td>0.031142</td>\n",
       "      <td>pp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ye</th>\n",
       "      <td>24.490710</td>\n",
       "      <td>2.424749</td>\n",
       "      <td>66.807727</td>\n",
       "      <td>-64.382978</td>\n",
       "      <td>0.036294</td>\n",
       "      <td>pp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twelfth</th>\n",
       "      <td>10.405212</td>\n",
       "      <td>1.415605</td>\n",
       "      <td>27.645040</td>\n",
       "      <td>-26.229435</td>\n",
       "      <td>0.051206</td>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fifteenth</th>\n",
       "      <td>8.613434</td>\n",
       "      <td>1.303478</td>\n",
       "      <td>22.632109</td>\n",
       "      <td>-21.328631</td>\n",
       "      <td>0.057594</td>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sixteenth</th>\n",
       "      <td>16.918258</td>\n",
       "      <td>2.634988</td>\n",
       "      <td>44.310013</td>\n",
       "      <td>-41.675026</td>\n",
       "      <td>0.059467</td>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thou</th>\n",
       "      <td>51.699027</td>\n",
       "      <td>8.402527</td>\n",
       "      <td>134.730931</td>\n",
       "      <td>-126.328405</td>\n",
       "      <td>0.062365</td>\n",
       "      <td>pp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ya</th>\n",
       "      <td>5.527337</td>\n",
       "      <td>1.177335</td>\n",
       "      <td>13.869558</td>\n",
       "      <td>-12.692223</td>\n",
       "      <td>0.084886</td>\n",
       "      <td>pp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eighteen</th>\n",
       "      <td>4.900906</td>\n",
       "      <td>1.205367</td>\n",
       "      <td>11.988029</td>\n",
       "      <td>-10.782662</td>\n",
       "      <td>0.100548</td>\n",
       "      <td>mc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fourteenth</th>\n",
       "      <td>8.848346</td>\n",
       "      <td>2.403725</td>\n",
       "      <td>21.207522</td>\n",
       "      <td>-18.803797</td>\n",
       "      <td>0.113343</td>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eleventh</th>\n",
       "      <td>4.214595</td>\n",
       "      <td>1.156311</td>\n",
       "      <td>10.079621</td>\n",
       "      <td>-8.923310</td>\n",
       "      <td>0.114718</td>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oh</th>\n",
       "      <td>16.807711</td>\n",
       "      <td>4.709339</td>\n",
       "      <td>40.009375</td>\n",
       "      <td>-35.300035</td>\n",
       "      <td>0.117706</td>\n",
       "      <td>uh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ah</th>\n",
       "      <td>9.387261</td>\n",
       "      <td>2.740107</td>\n",
       "      <td>22.134847</td>\n",
       "      <td>-19.394741</td>\n",
       "      <td>0.123792</td>\n",
       "      <td>uh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eighteenth</th>\n",
       "      <td>39.644826</td>\n",
       "      <td>11.605158</td>\n",
       "      <td>93.417926</td>\n",
       "      <td>-81.812768</td>\n",
       "      <td>0.124228</td>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thirteenth</th>\n",
       "      <td>8.171247</td>\n",
       "      <td>2.487821</td>\n",
       "      <td>19.070643</td>\n",
       "      <td>-16.582822</td>\n",
       "      <td>0.130453</td>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thirteen</th>\n",
       "      <td>5.771461</td>\n",
       "      <td>1.822066</td>\n",
       "      <td>13.345418</td>\n",
       "      <td>-11.523352</td>\n",
       "      <td>0.136531</td>\n",
       "      <td>mc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eighth</th>\n",
       "      <td>6.144556</td>\n",
       "      <td>1.955217</td>\n",
       "      <td>14.178667</td>\n",
       "      <td>-12.223450</td>\n",
       "      <td>0.137898</td>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nineteen</th>\n",
       "      <td>3.542102</td>\n",
       "      <td>1.170327</td>\n",
       "      <td>8.090576</td>\n",
       "      <td>-6.920249</td>\n",
       "      <td>0.144653</td>\n",
       "      <td>mc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ninth</th>\n",
       "      <td>5.688551</td>\n",
       "      <td>1.892145</td>\n",
       "      <td>12.969112</td>\n",
       "      <td>-11.076967</td>\n",
       "      <td>0.145896</td>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seventeen</th>\n",
       "      <td>4.233019</td>\n",
       "      <td>1.450645</td>\n",
       "      <td>9.568920</td>\n",
       "      <td>-8.118275</td>\n",
       "      <td>0.151600</td>\n",
       "      <td>mc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sixteen</th>\n",
       "      <td>5.564186</td>\n",
       "      <td>1.920177</td>\n",
       "      <td>12.552488</td>\n",
       "      <td>-10.632311</td>\n",
       "      <td>0.152972</td>\n",
       "      <td>mc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seventeenth</th>\n",
       "      <td>26.517400</td>\n",
       "      <td>9.355607</td>\n",
       "      <td>59.429444</td>\n",
       "      <td>-50.073837</td>\n",
       "      <td>0.157424</td>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ha</th>\n",
       "      <td>12.998455</td>\n",
       "      <td>4.597212</td>\n",
       "      <td>29.109945</td>\n",
       "      <td>-24.512733</td>\n",
       "      <td>0.157926</td>\n",
       "      <td>uh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unto</th>\n",
       "      <td>16.830742</td>\n",
       "      <td>6.005809</td>\n",
       "      <td>37.590266</td>\n",
       "      <td>-31.584456</td>\n",
       "      <td>0.159770</td>\n",
       "      <td>ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fourteen</th>\n",
       "      <td>6.407105</td>\n",
       "      <td>2.319630</td>\n",
       "      <td>14.245864</td>\n",
       "      <td>-11.926234</td>\n",
       "      <td>0.162828</td>\n",
       "      <td>mc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   fpm   fpm_phil     fpm_lit    fpm_diff   fpm_div    pos\n",
       "word                                                                      \n",
       "thy          46.199326   3.651140  127.796152 -124.145013  0.028570  appge\n",
       "thee         28.442756   2.438765   78.311934  -75.873169  0.031142     pp\n",
       "ye           24.490710   2.424749   66.807727  -64.382978  0.036294     pp\n",
       "twelfth      10.405212   1.415605   27.645040  -26.229435  0.051206     md\n",
       "fifteenth     8.613434   1.303478   22.632109  -21.328631  0.057594     md\n",
       "sixteenth    16.918258   2.634988   44.310013  -41.675026  0.059467     md\n",
       "thou         51.699027   8.402527  134.730931 -126.328405  0.062365     pp\n",
       "ya            5.527337   1.177335   13.869558  -12.692223  0.084886     pp\n",
       "eighteen      4.900906   1.205367   11.988029  -10.782662  0.100548     mc\n",
       "fourteenth    8.848346   2.403725   21.207522  -18.803797  0.113343     md\n",
       "eleventh      4.214595   1.156311   10.079621   -8.923310  0.114718     md\n",
       "oh           16.807711   4.709339   40.009375  -35.300035  0.117706     uh\n",
       "ah            9.387261   2.740107   22.134847  -19.394741  0.123792     uh\n",
       "eighteenth   39.644826  11.605158   93.417926  -81.812768  0.124228     md\n",
       "thirteenth    8.171247   2.487821   19.070643  -16.582822  0.130453     md\n",
       "thirteen      5.771461   1.822066   13.345418  -11.523352  0.136531     mc\n",
       "eighth        6.144556   1.955217   14.178667  -12.223450  0.137898     md\n",
       "nineteen      3.542102   1.170327    8.090576   -6.920249  0.144653     mc\n",
       "ninth         5.688551   1.892145   12.969112  -11.076967  0.145896     md\n",
       "seventeen     4.233019   1.450645    9.568920   -8.118275  0.151600     mc\n",
       "sixteen       5.564186   1.920177   12.552488  -10.632311  0.152972     mc\n",
       "seventeenth  26.517400   9.355607   59.429444  -50.073837  0.157424     md\n",
       "ha           12.998455   4.597212   29.109945  -24.512733  0.157926     uh\n",
       "unto         16.830742   6.005809   37.590266  -31.584456  0.159770     ii\n",
       "fourteen      6.407105   2.319630   14.245864  -11.926234  0.162828     mc"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.query('fpm_phil > 1 & fpm_lit > 1 & content_word==False')[['fpm','fpm_phil','fpm_lit','fpm_diff','fpm_div','pos']].sort_values('fpm_div',ascending=True).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f7af059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['theory',\n",
       " 'will',\n",
       " 'would',\n",
       " 'case',\n",
       " 'does',\n",
       " 'true',\n",
       " 'then',\n",
       " 'literary',\n",
       " 'poem',\n",
       " 'knowledge',\n",
       " 'being',\n",
       " 'belief',\n",
       " 'view',\n",
       " 'were',\n",
       " 'argument',\n",
       " 'been',\n",
       " 'have',\n",
       " 'text',\n",
       " 'moral',\n",
       " 'properties',\n",
       " 'english',\n",
       " 'reason',\n",
       " 'truth',\n",
       " 'work',\n",
       " 'cases',\n",
       " 'possible',\n",
       " 'account',\n",
       " 'different',\n",
       " 'problem',\n",
       " 'poetry',\n",
       " 'question',\n",
       " 'love',\n",
       " 'objects',\n",
       " 'given',\n",
       " 'literature',\n",
       " 'sense',\n",
       " 'principle',\n",
       " 'beliefs',\n",
       " 'certain',\n",
       " 'must',\n",
       " 'causal',\n",
       " 'fact',\n",
       " 'claim',\n",
       " 'object',\n",
       " 'history',\n",
       " 'should',\n",
       " 'science',\n",
       " 'novel',\n",
       " 'story',\n",
       " 'narrative',\n",
       " 'life',\n",
       " 'philosophy',\n",
       " 'play',\n",
       " 'poet',\n",
       " 'epistemic',\n",
       " 'might',\n",
       " 'logical',\n",
       " 'most',\n",
       " 'conditions',\n",
       " 'think',\n",
       " 'press',\n",
       " 'relevant',\n",
       " 'writing',\n",
       " 'things',\n",
       " 'theories',\n",
       " 'reasons',\n",
       " 'only',\n",
       " 'proposition',\n",
       " 'death',\n",
       " 'other',\n",
       " 'particular',\n",
       " 'book',\n",
       " 'logic',\n",
       " 'physical',\n",
       " 'just',\n",
       " 'concept',\n",
       " 'relation',\n",
       " 'property',\n",
       " 'system',\n",
       " 'reading',\n",
       " 'poems',\n",
       " 'experience',\n",
       " 'example',\n",
       " 'value',\n",
       " 'works',\n",
       " 'suppose']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 100\n",
    "word_df['fpm_div_log'] = word_df['fpm_div'].apply(np.log10)\n",
    "word_df['fpm_div_log_abs'] = word_df['fpm_div_log'].apply(abs)\n",
    "word_df['fpm_diff_abs'] = word_df['fpm_diff'].apply(abs)\n",
    "\n",
    "ok_pos = {'n','v','j','r'}\n",
    "feature_selection = word_df.sample(frac=1)\n",
    "\n",
    "feature_selection = feature_selection.query('pos0 in @ok_pos')\n",
    "feature_selection = feature_selection.sort_values('fpm_diff_abs', ascending=False).iloc[:n_features]\n",
    "feature_selection.iloc[0]\n",
    "\n",
    "WORDS_TO_FEATURE = feature_selection.index.tolist()\n",
    "WORDS_TO_FEATURE = [w for w in WORDS_TO_FEATURE if len(w)>3]\n",
    "WORDS_TO_FEATURE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66893757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hence</th>\n",
       "      <td>66887</td>\n",
       "      <td>rr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thus</th>\n",
       "      <td>224437</td>\n",
       "      <td>rr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>therefore</th>\n",
       "      <td>113948</td>\n",
       "      <td>rr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>because</th>\n",
       "      <td>269776</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count pos\n",
       "word                 \n",
       "hence       66887  rr\n",
       "thus       224437  rr\n",
       "therefore  113948  rr\n",
       "because    269776  cs"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df.loc[['hence','thus','therefore', 'because']][['count','pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f9dc3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>US_or_UK</th>\n",
       "      <th>fpm_BNC</th>\n",
       "      <th>fpm_COCA</th>\n",
       "      <th>fpm_COHA_1800s</th>\n",
       "      <th>fpm_COHA_1900-49</th>\n",
       "      <th>fpm_COHA_1950-89</th>\n",
       "      <th>fpm_SOAP</th>\n",
       "      <th>fpm_bnc_acad</th>\n",
       "      <th>fpm_bnc_fic</th>\n",
       "      <th>fpm_bnc_mag</th>\n",
       "      <th>...</th>\n",
       "      <th>fpm</th>\n",
       "      <th>fpm_phil</th>\n",
       "      <th>fpm_lit</th>\n",
       "      <th>fpm_diff</th>\n",
       "      <th>fpm_div</th>\n",
       "      <th>content_word</th>\n",
       "      <th>fpm_div_log</th>\n",
       "      <th>fpm_div_log_abs</th>\n",
       "      <th>fpm_diff_abs</th>\n",
       "      <th>pos0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td></td>\n",
       "      <td>59717.97</td>\n",
       "      <td>54124.71</td>\n",
       "      <td>65266.92</td>\n",
       "      <td>63479.96</td>\n",
       "      <td>59363.87</td>\n",
       "      <td>21403.42</td>\n",
       "      <td>73581.36</td>\n",
       "      <td>52467.51</td>\n",
       "      <td>58832.77</td>\n",
       "      <td>...</td>\n",
       "      <td>70157.163798</td>\n",
       "      <td>65449.558448</td>\n",
       "      <td>79185.178506</td>\n",
       "      <td>-13735.620059</td>\n",
       "      <td>0.826538</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.082737</td>\n",
       "      <td>0.082737</td>\n",
       "      <td>13735.620059</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td></td>\n",
       "      <td>25808.34</td>\n",
       "      <td>26636.86</td>\n",
       "      <td>33417.48</td>\n",
       "      <td>28577.44</td>\n",
       "      <td>26260.07</td>\n",
       "      <td>17677.41</td>\n",
       "      <td>26888.33</td>\n",
       "      <td>26803.23</td>\n",
       "      <td>26337.68</td>\n",
       "      <td>...</td>\n",
       "      <td>24934.743682</td>\n",
       "      <td>22059.512988</td>\n",
       "      <td>30448.720124</td>\n",
       "      <td>-8389.207136</td>\n",
       "      <td>0.724481</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.139973</td>\n",
       "      <td>0.139973</td>\n",
       "      <td>8389.207136</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td></td>\n",
       "      <td>30086.53</td>\n",
       "      <td>25782.79</td>\n",
       "      <td>37182.86</td>\n",
       "      <td>32184.17</td>\n",
       "      <td>27505.53</td>\n",
       "      <td>10067.32</td>\n",
       "      <td>45030.26</td>\n",
       "      <td>21465.10</td>\n",
       "      <td>26809.46</td>\n",
       "      <td>...</td>\n",
       "      <td>48616.624278</td>\n",
       "      <td>47353.473178</td>\n",
       "      <td>51039.033520</td>\n",
       "      <td>-3685.560341</td>\n",
       "      <td>0.927789</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.032551</td>\n",
       "      <td>0.032551</td>\n",
       "      <td>3685.560341</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td></td>\n",
       "      <td>20853.49</td>\n",
       "      <td>22240.78</td>\n",
       "      <td>20346.25</td>\n",
       "      <td>21357.82</td>\n",
       "      <td>22557.53</td>\n",
       "      <td>15632.54</td>\n",
       "      <td>20755.41</td>\n",
       "      <td>22470.99</td>\n",
       "      <td>23270.21</td>\n",
       "      <td>...</td>\n",
       "      <td>24075.924461</td>\n",
       "      <td>24496.357873</td>\n",
       "      <td>23269.637880</td>\n",
       "      <td>1226.719993</td>\n",
       "      <td>1.052718</td>\n",
       "      <td>False</td>\n",
       "      <td>0.022312</td>\n",
       "      <td>0.022312</td>\n",
       "      <td>1226.719993</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td></td>\n",
       "      <td>18307.46</td>\n",
       "      <td>17306.20</td>\n",
       "      <td>17775.94</td>\n",
       "      <td>17335.58</td>\n",
       "      <td>17055.21</td>\n",
       "      <td>6702.35</td>\n",
       "      <td>24739.06</td>\n",
       "      <td>13318.05</td>\n",
       "      <td>16743.76</td>\n",
       "      <td>...</td>\n",
       "      <td>24198.050975</td>\n",
       "      <td>23137.594312</td>\n",
       "      <td>26231.742766</td>\n",
       "      <td>-3094.148454</td>\n",
       "      <td>0.882046</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.054509</td>\n",
       "      <td>0.054509</td>\n",
       "      <td>3094.148454</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extratropical</th>\n",
       "      <td></td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spathe</th>\n",
       "      <td></td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ovules</th>\n",
       "      <td></td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gweilos</th>\n",
       "      <td></td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>starthistle</th>\n",
       "      <td></td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86403 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              US_or_UK   fpm_BNC  fpm_COCA  fpm_COHA_1800s  fpm_COHA_1900-49  \\\n",
       "word                                                                           \n",
       "the                     59717.97  54124.71        65266.92          63479.96   \n",
       "and                     25808.34  26636.86        33417.48          28577.44   \n",
       "of                      30086.53  25782.79        37182.86          32184.17   \n",
       "a                       20853.49  22240.78        20346.25          21357.82   \n",
       "in                      18307.46  17306.20        17775.94          17335.58   \n",
       "...                ...       ...       ...             ...               ...   \n",
       "extratropical               0.00      0.03            0.00              0.01   \n",
       "spathe                      0.00      0.03            0.01              0.03   \n",
       "ovules                      0.09      0.03            0.02              0.05   \n",
       "gweilos                     0.00      0.03            0.00              0.00   \n",
       "starthistle                 0.00      0.03            0.00              0.00   \n",
       "\n",
       "               fpm_COHA_1950-89  fpm_SOAP  fpm_bnc_acad  fpm_bnc_fic  \\\n",
       "word                                                                   \n",
       "the                    59363.87  21403.42      73581.36     52467.51   \n",
       "and                    26260.07  17677.41      26888.33     26803.23   \n",
       "of                     27505.53  10067.32      45030.26     21465.10   \n",
       "a                      22557.53  15632.54      20755.41     22470.99   \n",
       "in                     17055.21   6702.35      24739.06     13318.05   \n",
       "...                         ...       ...           ...          ...   \n",
       "extratropical              0.00      0.00          0.00         0.00   \n",
       "spathe                     0.01      0.00          0.00         0.00   \n",
       "ovules                     0.11      0.00          0.33         0.00   \n",
       "gweilos                    0.00      0.00          0.00         0.00   \n",
       "starthistle                0.00      0.00          0.00         0.00   \n",
       "\n",
       "               fpm_bnc_mag  ...           fpm      fpm_phil       fpm_lit  \\\n",
       "word                        ...                                             \n",
       "the               58832.77  ...  70157.163798  65449.558448  79185.178506   \n",
       "and               26337.68  ...  24934.743682  22059.512988  30448.720124   \n",
       "of                26809.46  ...  48616.624278  47353.473178  51039.033520   \n",
       "a                 23270.21  ...  24075.924461  24496.357873  23269.637880   \n",
       "in                16743.76  ...  24198.050975  23137.594312  26231.742766   \n",
       "...                    ...  ...           ...           ...           ...   \n",
       "extratropical         0.00  ...      0.000000      0.000000      0.000000   \n",
       "spathe                0.00  ...      0.000000      0.000000      0.000000   \n",
       "ovules                0.00  ...      0.000000      0.000000      0.000000   \n",
       "gweilos               0.00  ...      0.000000      0.000000      0.000000   \n",
       "starthistle           0.00  ...      0.000000      0.000000      0.000000   \n",
       "\n",
       "                   fpm_diff   fpm_div  content_word  fpm_div_log  \\\n",
       "word                                                               \n",
       "the           -13735.620059  0.826538         False    -0.082737   \n",
       "and            -8389.207136  0.724481         False    -0.139973   \n",
       "of             -3685.560341  0.927789         False    -0.032551   \n",
       "a               1226.719993  1.052718         False     0.022312   \n",
       "in             -3094.148454  0.882046         False    -0.054509   \n",
       "...                     ...       ...           ...          ...   \n",
       "extratropical      0.000000       NaN          True          NaN   \n",
       "spathe             0.000000       NaN          True          NaN   \n",
       "ovules             0.000000       NaN          True          NaN   \n",
       "gweilos            0.000000       NaN          True          NaN   \n",
       "starthistle        0.000000       NaN          True          NaN   \n",
       "\n",
       "               fpm_div_log_abs  fpm_diff_abs  pos0  \n",
       "word                                                \n",
       "the                   0.082737  13735.620059     a  \n",
       "and                   0.139973   8389.207136     c  \n",
       "of                    0.032551   3685.560341     i  \n",
       "a                     0.022312   1226.719993     a  \n",
       "in                    0.054509   3094.148454     i  \n",
       "...                        ...           ...   ...  \n",
       "extratropical              NaN      0.000000     j  \n",
       "spathe                     NaN      0.000000     n  \n",
       "ovules                     NaN      0.000000     n  \n",
       "gweilos                    NaN      0.000000     n  \n",
       "starthistle                NaN      0.000000     n  \n",
       "\n",
       "[86403 rows x 38 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcba244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58126/58126 [00:21<00:00, 2734.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing features...\n",
      "Running Leave-One-Out Classification...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# 5. Run LOO Classification\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# cross_val_predict with LOO is equivalent to the manual loop\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning Leave-One-Out Classification...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m y_pred = \u001b[43mcross_val_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# 6. Report Results\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Classifier Results (Phil vs Lit) ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ordinary-style-philosophy/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ordinary-style-philosophy/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1211\u001b[39m, in \u001b[36mcross_val_predict\u001b[39m\u001b[34m(estimator, X, y, groups, cv, n_jobs, verbose, params, pre_dispatch, method)\u001b[39m\n\u001b[32m   1208\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m   1209\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m   1210\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m-> \u001b[39m\u001b[32m1211\u001b[39m predictions = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1224\u001b[39m inv_test_indices = np.empty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype=\u001b[38;5;28mint\u001b[39m)\n\u001b[32m   1225\u001b[39m inv_test_indices[test_indices] = np.arange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ordinary-style-philosophy/venv/lib/python3.11/site-packages/sklearn/utils/parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ordinary-style-philosophy/venv/lib/python3.11/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ordinary-style-philosophy/venv/lib/python3.11/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/ordinary-style-philosophy/venv/lib/python3.11/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm\n",
    "from osp import get_corpus_metadata, HashStash\n",
    "\n",
    "# 1. Load Metadata\n",
    "df = get_corpus_metadata()\n",
    "# Filter for just Philosophy and Literature\n",
    "df_filtered = df[df['discipline'].isin(['Philosophy', 'Literature'])]\n",
    "ids = df_filtered.index.tolist()\n",
    "y = df_filtered['discipline'].values\n",
    "\n",
    "# 2. Load Features (Token Counts)\n",
    "# Assuming 'osp_counts' stash contains the counts as shown in GetFeatures.ipynb\n",
    "STASH_COUNTS = HashStash('osp_counts')\n",
    "features = []\n",
    "\n",
    "print(\"Loading features...\")\n",
    "for doc_id in tqdm(ids):\n",
    "    # Retrieve counts from stash\n",
    "    counts = STASH_COUNTS.get(doc_id, {})\n",
    "    features.append(counts)\n",
    "\n",
    "# 3. Vectorize features\n",
    "print(\"Vectorizing features...\")\n",
    "v = DictVectorizer(sparse=True)\n",
    "X = v.fit_transform(features)\n",
    "\n",
    "# 4. Initialize LOO and Logistic Regression\n",
    "loo = LeaveOneOut()\n",
    "clf = LogisticRegression(max_iter=1, solver='liblinear') # liblinear is often good for smaller/sparse datasets\n",
    "\n",
    "# 5. Run LOO Classification\n",
    "# cross_val_predict with LOO is equivalent to the manual loop\n",
    "print(\"Running Leave-One-Out Classification...\")\n",
    "y_pred = cross_val_predict(clf, X, y, cv=loo, n_jobs=-1)\n",
    "\n",
    "# 6. Report Results\n",
    "print(\"\\n--- Classifier Results (Phil vs Lit) ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y, y_pred):.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(pd.crosstab(pd.Series(y, name='Actual'), pd.Series(y_pred, name='Predicted')))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, y_pred))\n",
    "\n",
    "# Optional: Inspect top features\n",
    "clf.fit(X, y) # Fit on all data to see overall coefficients\n",
    "feature_names = v.get_feature_names_out()\n",
    "coefs = clf.coef_[0]\n",
    "top_phil = np.argsort(coefs)[:10]\n",
    "top_lit = np.argsort(coefs)[-10:]\n",
    "\n",
    "print(\"\\nTop features for Literature:\")\n",
    "for i in reversed(top_lit):\n",
    "    print(f\"{feature_names[i]}: {coefs[i]:.4f}\")\n",
    "\n",
    "print(\"\\nTop features for Philosophy:\")\n",
    "for i in top_phil:\n",
    "    print(f\"{feature_names[i]}: {coefs[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d62a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59e256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
