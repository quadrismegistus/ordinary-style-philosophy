{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ffc0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..')\n",
    "from osp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf43eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_current_feat_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f47fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for id,docstr in STASH_SLICES_NLP.items():\n",
    "    break\n",
    "# doc=stanza.Document.from_serialized(docstr)\n",
    "# sent = random.choice(doc.sentences)\n",
    "txt = \"\"\"\n",
    "These words, it seems to me, give us a particular picture of the\n",
    "essence of human language. It is this: the individual words in language\n",
    "name objects—sentences are combinations of such names.——In this\n",
    "picture of language we find the roots of the following idea: Every word\n",
    "has a meaning. This meaning is correlated with the word. It is the\n",
    "object for which the word stands.\n",
    "\"\"\"\n",
    "\n",
    "doc = get_nlp_doc(txt)\n",
    "sent = doc.sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_leaf(tree):\n",
    "    \"\"\"Check if a tree node is a leaf (preterminal) node.\"\"\"\n",
    "    return not isinstance(tree[0], nltk.Tree) if len(tree) > 0 else False\n",
    "\n",
    "\n",
    "def get_leaf_ids(tree):\n",
    "    print(tree)\n",
    "    return [word.id for word in tree.leaves()]\n",
    "\n",
    "def iter_preterms(tree):\n",
    "    for t in tree.subtrees():\n",
    "        if is_leaf(t):\n",
    "            yield t\n",
    "\n",
    "def tokenize_clauses(tree): # -> return both whether \"IC\" or \"DC\"\n",
    "    clause_num = 0\n",
    "    clause_type = None\n",
    "    for t in tree.subtrees():\n",
    "        ttxt = ' '.join(t.leaves())\n",
    "        if ttxt and ttxt[0].isalpha() and ((not is_in_sbar(t) and t.label() == 'S') or t.label() == 'SBAR'):\n",
    "            clause_num += 1\n",
    "            clause_type = 'DC' if is_in_sbar(t) else 'IC'\n",
    "\n",
    "        t._clause_num = clause_num\n",
    "        t._clause_type = clause_type\n",
    "\n",
    "    # o = defaultdict(list)\n",
    "    o = []\n",
    "    for preterm_i,preterm in enumerate(iter_preterms(tree)):\n",
    "        d = {\n",
    "            'clause_num': preterm._clause_num,\n",
    "            'clause_type': preterm._clause_type,\n",
    "            'word_num': preterm_i+1,\n",
    "            'word': ' '.join(preterm.leaves())\n",
    "        }\n",
    "        o.append(d)\n",
    "    \n",
    "    odf = pd.DataFrame(o)\n",
    "    odf['clause_num'] = odf['clause_num'].rank(method='dense', ascending=True).apply(int)\n",
    "    return odf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528020ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = get_nlp_doc(\"The trouble about progress is that it always looks much greater than it really is.\").sentences[0]\n",
    "# # sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed8284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clauses(sent):\n",
    "    if isinstance(sent, str):\n",
    "        sent = get_nlp_doc(sent).sentences[0]\n",
    "    tree = get_sent_tree(sent)\n",
    "    odf = tokenize_clauses(tree)\n",
    "    assert len(odf) == len(sent.words)\n",
    "    odf['pos'] = [w.xpos for w in sent.words]\n",
    "    odf['deprel'] = [w.deprel for w in sent.words]\n",
    "    odf['head'] = [w.head for w in sent.words]\n",
    "    return odf.set_index(['clause_num','clause_type','word_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afe6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_clauses(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ada7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a5d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def get_color(\n",
    "    feat,\n",
    "    color_by='weight',\n",
    "    df_feats=None,\n",
    "    vcenter=0.0,  # The \"clamping\" point for the neutral color\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "    cmap_name='RdBu' # Red (low) to White to Blue (high)\n",
    "):\n",
    "    if df_feats is None:\n",
    "        df_feats = get_current_feat_weights()\n",
    "    \n",
    "    val = df_feats.loc[feat, color_by] if feat in df_feats.index else 0\n",
    "    \n",
    "    # 1. Use provided bounds or calculate from data\n",
    "    if vmin is None:\n",
    "        vmin = df_feats[color_by].min()\n",
    "    if vmax is None:\n",
    "        vmax = df_feats[color_by].max()\n",
    "\n",
    "    # 2. Logic to handle the center point clamping\n",
    "    # TwoSlopeNorm requires vmin < vcenter < vmax\n",
    "    if vmin < vcenter < vmax:\n",
    "        norm = mcolors.TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "    else:\n",
    "        # Fallback if the range is entirely on one side of vcenter\n",
    "        norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    \n",
    "    # 3. Get the color\n",
    "    print(feat,val,vmin,vmax)\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "    rgba = cmap(norm(val))\n",
    "    return mcolors.to_hex(rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15fbcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_color('pos_NNPS',color_by='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48798509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manual_displacy_data(clause_df):\n",
    "    clause_data = {\n",
    "        \"words\": [{\"text\": text, \"tag\": pos} for text,pos in zip(clause_df['word'], clause_df['pos'])],\n",
    "        \"arcs\": [\n",
    "            {\n",
    "                \"start\": row['word_num']-1,\n",
    "                \"end\": row['head']-1,\n",
    "                \"label\": row['deprel'],\n",
    "                \"dir\": \"left\" if row['word_num'] > row['head'] else \"right\"\n",
    "            }\n",
    "            for _, row in clause_df.reset_index().iterrows()\n",
    "            if row['word_num'] < row['head']\n",
    "        ]\n",
    "    }\n",
    "    return clause_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6260587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clause_data = get_manual_displacy_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981fddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for clause, clause_df in df.groupby('clause_num'):\n",
    "#     clause_data = get_manual_displacy_data(clause_df)\n",
    "#     displacy.render(clause_data, style=\"dep\", manual=True)\n",
    "#     # x.render_to_file(f\"clause_{clause}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94e2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbe7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_by = 'weight'\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from spacy import displacy\n",
    "html_output = displacy.render(clause_data, style=\"dep\", manual=True,options={'compact': False},jupyter=False)\n",
    "\n",
    "# Parse the SVG\n",
    "soup = BeautifulSoup(html_output, 'html.parser')\n",
    "\n",
    "tag_elements = soup.find_all('tspan', class_='displacy-tag')\n",
    "for idx, tag_elem in enumerate(tag_elements):\n",
    "    color = get_color(f'pos_{tag_elem.text}', color_by=color_by)\n",
    "    # Use a thick stroke as a background, and set paint-order to draw stroke behind fill\n",
    "    tag_elem['style'] = f\"paint-order: stroke fill; stroke: {color}; stroke-width: 1em; stroke-linecap: round; stroke-linejoin: round;\"\n",
    "    tag_elem['fill'] = 'black'  # Keep the text itself black for readability\n",
    "\n",
    "deprel_elements = soup.find_all('textpath')\n",
    "for idx, deprel_elem in enumerate(deprel_elements):\n",
    "    color = get_color(f'deprel_{deprel_elem.text}', color_by=color_by)\n",
    "    # Apply the same background highlight effect to dependency labels\n",
    "    deprel_elem['style'] = f\"paint-order: stroke fill; stroke: {color}; stroke-width: .3em; font-size: 1.1em;\"\n",
    "    deprel_elem['fill'] = 'black'\n",
    "\n",
    "# # Combine and display\n",
    "HTML(str(soup))\n",
    "# # deprel_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(html_output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f894a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f88e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f69988",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.serve(clause_data, style=\"dep\", manual=True, port=5001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55d89bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format your Stanza data into this specific dictionary structure\n",
    "manual_data = {\n",
    "    \"words\": [\n",
    "        {\"text\": \"Barack\", \"tag\": \"PROPN\"},\n",
    "        {\"text\": \"Obama\", \"tag\": \"PROPN\"},\n",
    "        {\"text\": \"was\", \"tag\": \"AUX\"},\n",
    "        {\"text\": \"born\", \"tag\": \"VERB\"}\n",
    "    ],\n",
    "    \"arcs\": [\n",
    "        {\"start\": 0, \"end\": 1, \"label\": \"flat\", \"dir\": \"left\"},\n",
    "        {\"start\": 1, \"end\": 3, \"label\": \"nsubjpass\", \"dir\": \"left\"},\n",
    "        {\"start\": 2, \"end\": 3, \"label\": \"auxpass\", \"dir\": \"left\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "displacy.render(manual_data, style=\"dep\", manual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326795ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "claus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c6433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_displacy_data_from_sent(sent):\n",
    "    words = [{\"text\": word.text, \"tag\": word.xpos} for word in sent.words]\n",
    "    arcs = []\n",
    "    \n",
    "    for word in sent.words:\n",
    "        # Skip root dependencies (head == 0)\n",
    "        if word.head == 0:\n",
    "            continue\n",
    "        \n",
    "        # Convert from 1-based (Stanza) to 0-based (displaCy) indexing\n",
    "        start = word.head - 1  # head position (0-based)\n",
    "        end = word.id - 1      # current word position (0-based)\n",
    "        \n",
    "        # Skip self-loops (word pointing to itself)\n",
    "        if start == end:\n",
    "            continue\n",
    "        \n",
    "        # Determine direction\n",
    "        if start < end:\n",
    "            direction = \"left\"\n",
    "        else:\n",
    "            direction = \"right\"\n",
    "            # Swap start and end for right-pointing arcs\n",
    "            start, end = end, start\n",
    "        \n",
    "        arcs.append({\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"label\": word.deprel,\n",
    "            \"dir\": direction\n",
    "        })\n",
    "    \n",
    "    return {\"words\": words, \"arcs\": arcs}\n",
    "\n",
    "data = get_displacy_data_from_sent(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccff53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(data, style=\"dep\", manual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec1558b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f649676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
