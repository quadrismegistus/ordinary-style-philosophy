{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZhIry5Gg3kZ"
      },
      "outputs": [],
      "source": [
        "import sys; sys.path.append('..')\n",
        "from osp import *\n",
        "pd.options.display.max_colwidth = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_data(data, target_col='_target', cv=5, verbose=True, balance=False, normalize=False, **kwargs):\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import classification_report, accuracy_score\n",
        "    from sklearn.model_selection import cross_val_predict\n",
        "    import numpy as np\n",
        "\n",
        "    # Ensure data is clean (fill NaNs)\n",
        "    _data = data.copy()\n",
        "    if not target_col in _data.columns:\n",
        "        _data[target_col] = _data.index.str.split('/').str[0]\n",
        "\n",
        "    if balance:\n",
        "        min_target_size = min(_data[target_col].value_counts())\n",
        "        _data = _data.groupby(target_col).sample(n=min_target_size)\n",
        "        print(f'Balanced data: {min_target_size} samples per target')\n",
        "    \n",
        "    df_data = _data.drop(columns=[target_col])\n",
        "    for c in df_data:\n",
        "        df_data[c] = pd.to_numeric(df_data[c], errors='coerce')\n",
        "    X_data_norm = df_data.fillna(0).values\n",
        "    y_data = _data[target_col].fillna('').values\n",
        "\n",
        "    # Initialize Logistic Regression\n",
        "    model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Running {cv}-fold Cross-Validation on {len(X_data_norm)} samples...\")\n",
        "    \n",
        "    # Get predictions and probabilities for all items in the balanced set\n",
        "    y_pred = cross_val_predict(model, X_data_norm, y_data, cv=cv, n_jobs=1)\n",
        "    y_probas = cross_val_predict(model, X_data_norm, y_data, cv=cv, n_jobs=1, method='predict_proba')\n",
        "    \n",
        "    # Confidence is the maximum probability across classes\n",
        "    confidence_scores = np.max(y_probas, axis=1)\n",
        "\n",
        "    accuracy = accuracy_score(y_data, y_pred)\n",
        "    if verbose:\n",
        "        print(f\"\\nClassifier Results ({cv}-fold CV):\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(classification_report(y_data, y_pred))\n",
        "\n",
        "    # Fit on all data to get final feature weights\n",
        "    model.fit(X_data_norm, y_data)\n",
        "    feature_names = _data.drop(columns=[target_col]).columns\n",
        "\n",
        "    if len(model.classes_) <= 2:\n",
        "        # Binary case: coef_ is (1, n_features)\n",
        "        weights_df = pd.DataFrame({\n",
        "            'feature': feature_names,\n",
        "            'weight': model.coef_[0]\n",
        "        }).sort_values('weight', ascending=False)\n",
        "    else:\n",
        "        # Multi-class case: coef_ is (n_classes, n_features)\n",
        "        weights_df = pd.DataFrame(model.coef_.T, columns=model.classes_, index=feature_names)\n",
        "        weights_df.index.name = 'feature'\n",
        "        weights_df = weights_df.reset_index()\n",
        "\n",
        "    # Return a DataFrame of relevant information\n",
        "    test_label = ' / '.join(model.classes_)\n",
        "    results_df = pd.DataFrame({\n",
        "        'id': _data.index,\n",
        "        'true_label': y_data,\n",
        "        'pred_label': y_pred,\n",
        "        'test_label': test_label,\n",
        "        'confidence': confidence_scores,\n",
        "        'correct': (y_pred == y_data),\n",
        "        'accuracy': accuracy,\n",
        "        'support': _data.shape[0],\n",
        "    })\n",
        "    results_df.set_index('id', inplace=True)\n",
        "    return results_df, weights_df, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_meta = get_corpus_metadata(min_year=1925, max_year=2025)\n",
        "df_phil = df_meta[df_meta['discipline'] == 'Philosophy']\n",
        "df_lit = df_meta[df_meta['discipline'] == 'Literature']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_balanced_cv_data(groups_train, target_col='discipline', balance=True, normalize=True):\n",
        "    df_meta = get_corpus_metadata()\n",
        "    name1, query1 = groups_train[0]\n",
        "    name2, query2 = groups_train[1]\n",
        "\n",
        "    df_meta1 = df_meta.query(query1)\n",
        "    df_meta2 = df_meta.query(query2)\n",
        "\n",
        "    \n",
        "    df_scores1 = get_feat_counts(df_meta1.index.tolist(), normalize=normalize)\n",
        "    df_scores2 = get_feat_counts(df_meta2.index.tolist(), normalize=normalize)\n",
        "\n",
        "    df_scores_cv = pd.concat([df_scores1, df_scores2]).assign(_type='CV')\n",
        "    df_scores_cv['_target'] = [get_text_metadata(i).get(target_col) for i in tqdm(df_scores_cv.index)]\n",
        "    df_scores_cv = df_scores_cv.dropna(subset=['_target'])\n",
        "    if balance:\n",
        "        df_scores_cv = df_scores_cv.groupby('_target').sample(n=min(df_scores_cv['_target'].value_counts()))\n",
        "\n",
        "    df_scores_all = get_all_feats(normalize=True).fillna(0)\n",
        "    df_scores_all['_target'] = [get_text_metadata(i).get(target_col) for i in tqdm(df_scores_all.index)]\n",
        "    df_scores_all = df_scores_all.dropna(subset=['_target'])\n",
        "    df_scores_rest = df_scores_all.drop(df_scores_cv.index).assign(_type='Unseen')\n",
        "\n",
        "    df_scores = pd.concat([df_scores_cv, df_scores_rest])\n",
        "    return df_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "groups_train = [\n",
        "    ('C21 Philosophy', 'discipline==\"Philosophy\" & 2000<=year<2025'),\n",
        "    ('C21 Literature', 'discipline==\"Literature\" & 2000<=year<2025'),\n",
        "]\n",
        "\n",
        "# df_scores = get_balanced_cv_data(groups_train)\n",
        "# df_scores.groupby(['_type','_target']).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cv_preds, cv_feats, cv_model = classify_data(\n",
        "#     df_scores.query('_type==\"CV\"').drop(columns=['_type']),\n",
        "#     target_col='_target',\n",
        "#     cv=5,\n",
        "#     verbose=True,\n",
        "#     balance=True\n",
        "# )\n",
        "# cv_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_then_predict(groups_train, target_col='discipline', balance=True, num_runs=1):\n",
        "    l_preds=[]\n",
        "    l_feats=[]\n",
        "    for nrun in range(num_runs):\n",
        "        df_scores = get_balanced_cv_data(groups_train, target_col=target_col, balance=balance)\n",
        "\n",
        "        cv_preds, cv_feats, cv_model = classify_data(\n",
        "            df_scores.query('_type==\"CV\"').drop(columns=['_type']),\n",
        "            target_col='_target',\n",
        "            cv=5,\n",
        "            verbose=True,\n",
        "            balance=True\n",
        "        )\n",
        "        \n",
        "        new_target = df_scores._target.tolist()\n",
        "        new_probs = cv_model.predict_proba(df_scores.drop(columns=['_type','_target']))\n",
        "        df_new_probs = pd.DataFrame(new_probs)\n",
        "        df_new_probs.columns = cv_model.classes_\n",
        "        df_new_probs['pred_label'] = df_new_probs.idxmax(axis=1)\n",
        "        df_new_probs.columns = ['prob1','prob2','pred_label']\n",
        "        df_new_probs['true_label'] = new_target\n",
        "        df_new_probs['test_label'] = ' / '.join(cv_model.classes_)\n",
        "        df_new_probs['id'] = df_scores.index\n",
        "        df_new_probs['predict_type'] = 'unseen'\n",
        "        df_new_probs.set_index('id', inplace=True)\n",
        "        # df_new_probs\n",
        "        l_preds.append(df_new_probs)\n",
        "        l_feats.append(cv_feats)\n",
        "    \n",
        "    df_preds = pd.concat(l_preds)\n",
        "    df_feats = pd.concat(l_feats)\n",
        "    return df_preds, get_df_feats_with_pos_mdw(df_feats, groups_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12789/12789 [00:00<00:00, 40805.35it/s]\n",
            "100%|██████████| 33665/33665 [00:00<00:00, 42564.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Balanced data: 3110 samples per target\n",
            "Running 5-fold Cross-Validation on 6220 samples...\n",
            "\n",
            "Classifier Results (5-fold CV):\n",
            "Accuracy: 0.6471\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Literature       0.64      0.66      0.65      3110\n",
            "  Philosophy       0.65      0.63      0.64      3110\n",
            "\n",
            "    accuracy                           0.65      6220\n",
            "   macro avg       0.65      0.65      0.65      6220\n",
            "weighted avg       0.65      0.65      0.65      6220\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_preds, df_feats = classify_then_predict(groups_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_preds.groupby('pred_label').mean(numeric_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_preds['text_id'] = [i.split('__')[0] for i in df_preds.index]\n",
        "odf = df_preds.rename_axis('slice_id').reset_index().merge(get_corpus_metadata(), left_on='text_id', right_on='id', how='left')\n",
        "odf.to_excel('../data/preds2.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "odf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
